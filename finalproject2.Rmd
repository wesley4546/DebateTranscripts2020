---
title: "2020 Democratic Debate - Topic Modeling"
date: "`r Sys.Date()`"
author: "Wesley Gardiner"
output:
  rmdformats::html_clean:
    highlight: kate
---


```{r setup, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
```


## Introduction

While I was looking at datasets for this final report I stumbled upon a interesting data set on Kaggle from the 2020 Democratic Debate transcripts. After recently learning about topic modeling I decided to choose that data set and apply my new topic modeling skills to answer some questions I had:

 * What topics were most common among the candidates?
 * Who talked the most?
 * What were the differnet speaking styles of the candidates?
 
 
**Another important thing I should mention, is that I only looked at candidates that stayed until the end of the debate series.**
 
So lets get started!

## Getting the Data

As mentioned previous, I was able to get the data from Kaggle.com

Full link: https://www.kaggle.com/brandenciranni/democratic-debate-transcripts-2020


## Importing the Data

Here are some packages I used to do my inital cleaning

```{r}
library(tidyverse)
library(tidytext)
library(lubridate)
library(stringr)
library(ggplot2)
library(tidyr)
```

If you don't have these don't fret! You can download them using these commands
```{r,eval=FALSE}
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("lubridate")
# install.packages("stringr")
# install.packages("ggplot2")
# install.packages("tidyr")
```


First thing I need to do is read the data into R (Since the data comes in a CSV format, I use the `read.csv()` function)


```{r read_csv()ing the data}
#Reads the data in from csv format
debate_data <-
  read.csv(
    here::here("data", "raw", "debate_transcripts_v3_2020-02-26.csv"),
    stringsAsFactors = FALSE,
    encoding = "UTF-8"
  )


debate_data <- tibble(debate_data)
```

I specify stringAsFactors = FALSE because I don't want the function to read characters or strings an label them as factors. I also specify an encoding of "UTF-8" because there was some conflict between the characters encoding from the original data set.


Great! Now lets take a peek into our data

```{r}
#Structure of the data
str(debate_data)

#Names of the columns
colnames(debate_data)

#This takes a look at the dimensions of our data in a clear format
paste("Our data has",nrow(debate_data),"rows and", ncol(debate_data),"columns")
```

## Descriptive Statistics

One of my questions was: Who talked the most?

```{r fig.width=10, fig.height=10}

#This will filter out only the last debate items
list_of_speakers_last <-
  debate_data %>% 
  filter(debate_name == "South Carolina Democratic Debate Transcript: February 25 Democratic Debate")

#This gives the names of the speakers in the last debate
unique(list_of_speakers_last$speaker)

#This is a list of the candidates of the last debate
list_of_candidates_last <- c("Bernie Sanders","Joe Biden","Elizabeth Warren","Michael Bloomberg","Pete Buttigieg","Tom Steyer","Amy Klobuchar")


#There were some speaking times of 0 (which doesn't seem to make sense) so I replaced them with 1 second.
debate_data <-
  debate_data %>% 
  mutate(speaking_time_seconds = ifelse(speaking_time_seconds == 0, 1, speaking_time_seconds))

#Here I am going to graph the speaking time in minutes for our candidates
speaking_time_graph <- 
  debate_data %>% 
  tidyr::drop_na() %>% #Drops NA
  group_by(speaker) %>% # I have to tell it to group by speaker because there are multiple rows of own speaker
  filter(speaker %in% list_of_candidates_last) %>% 
  summarise(total_speaking_time_minutes = sum(speaking_time_seconds)/60) %>%  #Creates our minutes column
  mutate(speaker = fct_reorder(speaker, total_speaking_time_minutes)) %>% #reoders for clarity
  ggplot(aes(speaker, total_speaking_time_minutes)) +
  geom_col()

#Cleans it up a little bit and adds labels
speaking_time_graph +
  labs(
    title = "Total Speaking Time in Minutes",
    subtitle = "2020 Democratic Debates",
    x = "Speaker",
    y = "Speaking Time in Minutes"
  ) +
  theme_bw() +
  geom_text(aes(label=round(total_speaking_time_minutes)), position=position_dodge(width=0.9), vjust=-0.25)

```



So we can see here that Sanders had the most speaking time (157 minutes) and Bloomberg had the least (27 minutes) and that makes sense because Bloomberg didn't have start his campaign until later.



